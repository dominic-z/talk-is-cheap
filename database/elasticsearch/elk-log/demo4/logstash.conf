input {
  # 通过5044端口来接收beats发送来的数据
    beats {
      port => 5044
	    ssl => false
    }
}

# 对日志结构进行解析处理
# 
filter {
     grok {
        # 筛选过滤
        # grok 里边有定义好的现场的模板你可以用，但是更多的是自定义模板，规则是这样的，小括号里边包含所有一个key和value，例子：（?<key>value），比如以下的信息，第一个我定义的key是data，表示方法为：?<key> 前边一个问号，然后用<>把key包含在里边去。value就是纯正则了，这个我就不举例子了。这个有个在线的调试库，可以供大家参考，
        # http://grokdebug.herokuapp.com/
        # 推测：这个应该就是对input的内容做解析过滤，比如(?<msg>.*)，就会把.*这个正则匹配的内容命名为msg，然后输出到output之中。es中最后可以看到这些字段
        # 而%{LOGLEVEL:level}，应该就是有一些grok内置的正则规则，这个规则叫做LOGLEVEL，匹配的内容命名为level
        # %{GREEDYDATA:thread}中，GREEDYDATA我猜可能就是尽可能多的匹配吧
        match => {
           "message" => "(?<timestamp>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3}) %{GREEDYDATA:thread} %{LOGLEVEL:level} %{GREEDYDATA:class} - (?<msg>.*)"
        }
	      remove_field => ["message"]
     }
	# 不匹配正则则删除，匹配正则用=~
     if [level] !~ "(ERROR|WARN|INFO)" {
         # 删除日志
         drop {}
     }
}


output {
  stdout {
    codec => rubydebug
  }


  if [fields][logtype] == "pre"{
    elasticsearch {
      hosts => ["http://es:9200"]
      # 用来配置es的用户和密码，我没有配置，所以注释掉
      # user => elastic
      # password => xxx
      index => "pre"
    }
  }
  if [fields][logtype] == "prex"{
    elasticsearch {
      hosts => ["http://es:9200"]
      # user => elastic
      # password => xxx
      index => "prex"
    }
  }
}